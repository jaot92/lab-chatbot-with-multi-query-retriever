{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering with LangChain, OpenAI, and MultiQuery Retriever\n",
    "\n",
    "This interactive workbook demonstrates example of Elasticsearch's [MultiQuery Retriever](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html) to generate similar queries for a given user input and apply all queries to retrieve a larger set of relevant documents from a vectorstore.\n",
    "\n",
    "Before we begin, we first split the fictional workplace documents into passages with `langchain` and uses OpenAI to transform these passages into embeddings and then store these into Elasticsearch.\n",
    "\n",
    "We will then ask a question, generate similar questions using langchain and OpenAI, retrieve relevant passages from the vector store, and use langchain and OpenAI again to provide a summary for the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install -qU jq lark langchain langchain-elasticsearch langchain_openai tiktoken\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elasticsearch\n",
    "\n",
    "‚ÑπÔ∏è We're using an Elastic Cloud deployment of Elasticsearch for this notebook. If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial. \n",
    "\n",
    "We'll use the **Cloud ID** to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to https://cloud.elastic.co/deployments and select your deployment.\n",
    "\n",
    "We will use [ElasticsearchStore](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html) to connect to our elastic cloud deployment, This would help create and index data easily.  We would also send list of documents that we created in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener las variables de entorno\n",
    "ELASTIC_CLOUD_ID = os.getenv(\"ELASTIC_CLOUD_ID\")\n",
    "ELASTIC_API_KEY = os.getenv(\"ELASTIC_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\"\"\"\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID \")\n",
    "\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
    "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
    "\n",
    "# https://platform.openai.com/api-keys\n",
    "OPENAI_API_KEY = getpass(\"OpenAI API key: \")\n",
    "\n",
    "\"\"\"\n",
    "# Verificar que tenemos todas las claves necesarias\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"No se encontr√≥ OPENAI_API_KEY en las variables de entorno\")\n",
    "if not ELASTIC_CLOUD_ID:\n",
    "    raise ValueError(\"No se encontr√≥ ELASTIC_CLOUD_ID en las variables de entorno\")\n",
    "if not ELASTIC_API_KEY:\n",
    "    raise ValueError(\"No se encontr√≥ ELASTIC_API_KEY en las variables de entorno\")\n",
    "\n",
    "# Configurar OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# Inicializar embeddings y vectorstore\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "try:\n",
    "    vectorstore = ElasticsearchStore(\n",
    "        es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "        es_api_key=ELASTIC_API_KEY,\n",
    "        index_name=\"my_index\", #give it a meaningful name,\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "    print(\"‚úÖ Conexi√≥n exitosa a Elasticsearch\")\n",
    "    print(f\"üîó Conectado al √≠ndice: my_index\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error al conectar con Elasticsearch:\")\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Data into Elasticsearch\n",
    "Let's download the sample dataset and deserialize the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/example-apps/chatbot-rag-app/data/data.json\"\n",
    "\n",
    "response = urlopen(url)\n",
    "data = json.load(response)\n",
    "\n",
    "with open(\"temp.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Documents into Passages\n",
    "\n",
    "We‚Äôll chunk documents into passages in order to improve the retrieval specificity and to ensure that we can provide multiple passages within the context window of the final question answering prompt.\n",
    "\n",
    "Here we are chunking documents into 800 token passages with an overlap of 400 tokens.\n",
    "\n",
    "Here we are using a simple splitter but Langchain offers more advanced splitters to reduce the chance of context being lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (0.3.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (0.3.17)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (0.3.33)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (0.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/LangChainWeek/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    #Populate the metadata dictionary with keys name, summary, url, category, and updated_at.\n",
    "    # Usar .get() con valores por defecto para manejar campos faltantes\n",
    "    metadata[\"name\"] = record.get(\"name\", \"\")\n",
    "    metadata[\"summary\"] = record.get(\"summary\", \"\")\n",
    "    metadata[\"url\"] = record.get(\"url\", \"\")\n",
    "    metadata[\"category\"] = record.get(\"category\", \"\")\n",
    "    metadata[\"updated_at\"] = record.get(\"updated_at\", \"\")\n",
    "    return metadata\n",
    "\n",
    "\n",
    "# For more loaders https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "# And 3rd party loaders https://python.langchain.com/docs/modules/data_connection/document_loaders/#third-party-loaders\n",
    "loader = JSONLoader(\n",
    "    file_path=\"temp.json\",\n",
    "    jq_schema=\".[]\",\n",
    "    content_key=\"content\",\n",
    "    metadata_func=metadata_func,\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=800, chunk_overlap=400 #define chunk size and chunk overlap\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk Import Passages\n",
    "\n",
    "Now that we have split each document into the chunk size of 800, we will now index data to elasticsearch using [ElasticsearchStore.from_documents](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html#langchain.vectorstores.elasticsearch.ElasticsearchStore.from_documents).\n",
    "\n",
    "We will use Cloud ID, Password and Index name values set in the `Create cloud deployment` step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'my_index'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Crear el cliente de Elasticsearch\n",
    "es_client = Elasticsearch(\n",
    "    cloud_id=ELASTIC_CLOUD_ID,\n",
    "    api_key=ELASTIC_API_KEY,\n",
    ")\n",
    "\n",
    "# Definir el mapeo correcto para el √≠ndice\n",
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"metadata\": {\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"keyword\"},\n",
    "                    \"summary\": {\"type\": \"text\"},\n",
    "                    \"url\": {\"type\": \"keyword\"},\n",
    "                    \"category\": {\"type\": \"keyword\"},\n",
    "                    \"updated_at\": {\"type\": \"date\", \"ignore_malformed\": True}\n",
    "                }\n",
    "            },\n",
    "            \"vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 1536,  # Dimensi√≥n para embeddings de OpenAI\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Eliminar el √≠ndice si existe\n",
    "if es_client.indices.exists(index=\"my_index\"):\n",
    "    es_client.indices.delete(index=\"my_index\")\n",
    "\n",
    "# Crear el √≠ndice con el mapeo\n",
    "es_client.indices.create(index=\"my_index\", body=index_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documentos indexados correctamente\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el vectorstore con m√°s par√°metros\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=\"my_index\",\n",
    "    embedding=embeddings,\n",
    "    distance_strategy=\"COSINE\",\n",
    ")\n",
    "\n",
    "# Intentar indexar los documentos con manejo de errores y configuraci√≥n correcta\n",
    "try:\n",
    "    documents = vectorstore.from_documents(\n",
    "        docs,\n",
    "        embeddings,\n",
    "        index_name=\"my_index\",\n",
    "        es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "        es_api_key=ELASTIC_API_KEY,\n",
    "        bulk_kwargs={\n",
    "            \"timeout\": \"100s\",\n",
    "            \"request_timeout\": 100,\n",
    "            \"chunk_size\": 50,  # Reducir el tama√±o del chunk\n",
    "            \"max_retries\": 3\n",
    "        }\n",
    "    )\n",
    "    print(\"‚úÖ Documentos indexados correctamente\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al indexar documentos: {str(e)}\")\n",
    "    if hasattr(e, 'errors'):\n",
    "        print(\"\\nDetalles del error:\")\n",
    "        for error in e.errors[:3]:\n",
    "            print(f\"- {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vectorstore.as_retriever(), llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering with MultiQuery Retriever\n",
    "\n",
    "Now that we have the passages stored in Elasticsearch, we can now ask a question to get the relevant passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide information on the sales team at NASA?', '2. How does the sales team operate within NASA?', '3. What are the responsibilities of the NASA sales team?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Answer ----\n",
      "The NASA sales team is a part of the Americas region in the sales organization of the company. It is led by two Area Vice-Presidents, Laura Martinez for North America and Gary Johnson for South America. The team is responsible for promoting and selling the company's products and services in the North and South American markets. They work closely with other departments, such as marketing, product development, and customer support, to ensure the company's success in these regions.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import format_document\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "LLM_CONTEXT_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Be as verbose and educational in your response as possible. \n",
    "    \n",
    "    context: {context}\n",
    "    Question: \"{question}\"\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "LLM_DOCUMENT_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "---\n",
    "SOURCE: {name}\n",
    "{page_content}\n",
    "---\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=LLM_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "_context = RunnableParallel(\n",
    "    context=retriever | _combine_documents,\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "chain = _context | LLM_CONTEXT_PROMPT | llm\n",
    "\n",
    "ans = chain.invoke(\"what is the nasa sales team?\")\n",
    "\n",
    "print(\"---- Answer ----\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate at least two new iteratioins of the previous cells - Be creative.** Did you master Multi-\n",
    "Query Retriever concepts through this lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Consultando pol√≠ticas de trabajo remoto...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. ¬øQu√© medidas se han implementado en la empresa para facilitar el trabajo remoto?', '2. ¬øC√≥mo ha adaptado la empresa sus pol√≠ticas de trabajo ante la situaci√≥n actual?', '3. ¬øExisten pol√≠ticas espec√≠ficas para el trabajo remoto en la empresa y cu√°les son?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Respuesta:\n",
      "\n",
      "La pol√≠tica de trabajo remoto de nuestra empresa se implement√≥ en marzo de 2020 con el prop√≥sito de proporcionar pautas y apoyo a los empleados para realizar su trabajo de manera remota durante la pandemia de COVID-19 y en el futuro. Esta pol√≠tica se aplica a todos los empleados elegibles, quienes deben obtener la aprobaci√≥n de su supervisor directo y el departamento de recursos humanos para trabajar desde casa. Se proporcionar√° el equipo y los recursos necesarios para el trabajo remoto, y se espera que los empleados mantengan una comunicaci√≥n efectiva con sus supervisores y colegas. Tambi√©n se espera que los empleados mantengan el mismo nivel de rendimiento y productividad que si estuvieran trabajando en la oficina. Adem√°s, se deben seguir las pol√≠ticas de confidencialidad y seguridad de datos, y se alienta a los empleados a priorizar su salud y bienestar mientras trabajan desde casa. Esta pol√≠tica se revisar√° peri√≥dicamente y se actualizar√° seg√∫n sea necesario. Si tiene alguna pregunta o inquietud, comun√≠quese con su supervisor o el departamento de recursos humanos.\n"
     ]
    }
   ],
   "source": [
    "# Primera iteraci√≥n - Pol√≠ticas de empresa\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import format_document\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "# Prompt template para pol√≠ticas\n",
    "POLICY_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Eres un asistente especializado en pol√≠ticas empresariales. \n",
    "    Utiliza el siguiente contexto para responder la pregunta de manera detallada y profesional.\n",
    "    Si no encuentras la informaci√≥n espec√≠fica, ind√≠calo claramente.\n",
    "    \n",
    "    Contexto: {context}\n",
    "    Pregunta: \"{question}\"\n",
    "    Respuesta:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Configuraci√≥n del chain\n",
    "_context = RunnableParallel(\n",
    "    context=retriever | _combine_documents,\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "policy_chain = _context | POLICY_PROMPT | llm\n",
    "\n",
    "# Probar con una pregunta sobre pol√≠ticas\n",
    "print(\"üîç Consultando pol√≠ticas de trabajo remoto...\")\n",
    "response = policy_chain.invoke(\"¬øCu√°les son las pol√≠ticas de trabajo remoto en la empresa?\")\n",
    "print(\"\\nüìã Respuesta:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ An√°lisis t√©cnico completo para: el sistema de gesti√≥n de documentos\n",
      "==================================================\n",
      "\n",
      "üìä Consultando: ¬øCu√°les son las especificaciones t√©cnicas de el sistema de gesti√≥n de documentos?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. ¬øQu√© caracter√≠sticas t√©cnicas tiene el sistema de gesti√≥n de documentos?', '2. ¬øPuedes darme detalles sobre las especificaciones t√©cnicas del sistema de gesti√≥n de documentos?', '3. ¬øCu√°les son las especificaciones t√©cnicas m√°s importantes del sistema de gesti√≥n de documentos?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado:\n",
      "\n",
      "Las especificaciones t√©cnicas de un sistema de gesti√≥n de documentos pueden variar dependiendo del proveedor y las necesidades espec√≠ficas de la empresa. Sin embargo, algunas de las caracter√≠sticas y requisitos comunes incluyen:\n",
      "\n",
      "1. Almacenamiento en la nube: El sistema debe permitir el almacenamiento de documentos en la nube para facilitar el acceso y la colaboraci√≥n en tiempo real.\n",
      "\n",
      "2. Seguridad: El sistema debe contar con medidas de seguridad robustas para proteger la informaci√≥n confidencial y evitar accesos no autorizados.\n",
      "\n",
      "3. Integraci√≥n con otros sistemas: Es importante que el sistema pueda integrarse con otros sistemas utilizados en la empresa, como el correo electr√≥nico o el sistema de gesti√≥n de clientes.\n",
      "\n",
      "4. Control de versiones: El sistema debe permitir la gesti√≥n de versiones de los documentos, para poder realizar un seguimiento de los cambios y revertir a versiones anteriores si es necesario.\n",
      "\n",
      "5. B√∫squeda avanzada: El sistema debe contar con una funci√≥n de b√∫squeda avanzada que permita encontrar documentos por palabras clave, fechas, etiquetas, etc.\n",
      "\n",
      "6. Personalizaci√≥n: El sistema debe permitir la personalizaci√≥n de la interfaz y la configuraci√≥n de permisos\n",
      "\n",
      "------------------------------\n",
      "\n",
      "üìä Consultando: ¬øQu√© requisitos de sistema tiene el sistema de gesti√≥n de documentos?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. ¬øCu√°les son los requerimientos de hardware para el sistema de gesti√≥n de documentos?', '2. ¬øQu√© especificaciones t√©cnicas son necesarias para el sistema de gesti√≥n de documentos?', '3. ¬øCu√°les son los componentes necesarios para el sistema de gesti√≥n de documentos?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado:\n",
      "\n",
      "El sistema de gesti√≥n de documentos puede tener diferentes requisitos de sistema dependiendo de su funcionalidad y caracter√≠sticas espec√≠ficas. Sin embargo, algunos requisitos comunes pueden incluir:\n",
      "\n",
      "1. Sistema operativo: El sistema de gesti√≥n de documentos puede requerir un sistema operativo espec√≠fico, como Windows, Mac o Linux, para funcionar correctamente.\n",
      "\n",
      "2. Espacio de almacenamiento: Dependiendo del tama√±o y la cantidad de documentos que se gestionen, el sistema puede requerir un cierto espacio de almacenamiento en disco para guardar los archivos.\n",
      "\n",
      "3. Memoria RAM: El sistema puede requerir una cantidad m√≠nima de memoria RAM para funcionar de manera eficiente y procesar grandes cantidades de datos.\n",
      "\n",
      "4. Procesador: Un procesador r√°pido y potente puede ser necesario para manejar grandes cantidades de documentos y realizar tareas de b√∫squeda y organizaci√≥n de manera eficiente.\n",
      "\n",
      "5. Conexi√≥n a internet: Si el sistema de gesti√≥n de documentos es basado en la nube, puede requerir una conexi√≥n a internet estable para acceder y almacenar los documentos.\n",
      "\n",
      "6. Seguridad: Es importante que el sistema de gesti√≥n de documentos tenga medidas de seguridad adecuadas para proteger la informaci√≥n conf\n",
      "\n",
      "------------------------------\n",
      "\n",
      "üìä Consultando: ¬øCu√°les son las caracter√≠sticas de seguridad de el sistema de gesti√≥n de documentos?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. ¬øQu√© medidas de seguridad se implementan en el sistema de gesti√≥n de documentos?', '2. ¬øC√≥mo se protegen los documentos en el sistema de gesti√≥n de documentos?', '3. ¬øCu√°les son las funciones de seguridad incorporadas en el sistema de gesti√≥n de documentos?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado:\n",
      "\n",
      "El sistema de gesti√≥n de documentos es una herramienta esencial para cualquier empresa u organizaci√≥n, ya que permite almacenar, organizar y gestionar de manera eficiente y segura toda la informaci√≥n y documentos importantes. Por lo tanto, es importante que este sistema cuente con caracter√≠sticas de seguridad s√≥lidas para proteger la informaci√≥n confidencial y sensible de la empresa.\n",
      "\n",
      "Algunas de las caracter√≠sticas de seguridad que debe tener un sistema de gesti√≥n de documentos son:\n",
      "\n",
      "1. Acceso restringido: El sistema debe permitir restringir el acceso a ciertos documentos o carpetas solo a usuarios autorizados. Esto se puede lograr mediante la asignaci√≥n de permisos y roles a cada usuario, lo que garantiza que solo puedan acceder a la informaci√≥n que necesitan para realizar sus tareas.\n",
      "\n",
      "2. Autenticaci√≥n de usuarios: Es importante que el sistema cuente con un sistema de autenticaci√≥n s√≥lido para garantizar que solo los usuarios autorizados puedan acceder al sistema. Esto puede incluir la autenticaci√≥n mediante contrase√±as, c√≥digos de acceso o incluso la autenticaci√≥n biom√©trica.\n",
      "\n",
      "3. Registro de actividad: El sistema debe tener la capacidad de registrar y auditar\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Segunda iteraci√≥n - Especificaciones t√©cnicas\n",
    "# Prompt template para an√°lisis t√©cnico\n",
    "TECHNICAL_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Eres un experto t√©cnico. Analiza la siguiente informaci√≥n y proporciona una respuesta \n",
    "    detallada y t√©cnicamente precisa. Incluye especificaciones cuando sea posible.\n",
    "    \n",
    "    Informaci√≥n disponible: {context}\n",
    "    Consulta t√©cnica: \"{question}\"\n",
    "    \n",
    "    An√°lisis t√©cnico:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Configuraci√≥n del chain t√©cnico\n",
    "technical_chain = _context | TECHNICAL_PROMPT | llm\n",
    "\n",
    "# Funci√≥n para realizar m√∫ltiples consultas t√©cnicas\n",
    "def analyze_technical_aspects(product_name: str):\n",
    "    print(f\"üî¨ An√°lisis t√©cnico completo para: {product_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Lista de aspectos t√©cnicos a consultar\n",
    "    aspects = [\n",
    "        f\"¬øCu√°les son las especificaciones t√©cnicas de {product_name}?\",\n",
    "        f\"¬øQu√© requisitos de sistema tiene {product_name}?\",\n",
    "        f\"¬øCu√°les son las caracter√≠sticas de seguridad de {product_name}?\"\n",
    "    ]\n",
    "    \n",
    "    for aspect in aspects:\n",
    "        print(f\"\\nüìä Consultando: {aspect}\")\n",
    "        response = technical_chain.invoke(aspect)\n",
    "        print(f\"Resultado:\\n{response}\\n\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Probar el an√°lisis t√©cnico\n",
    "analyze_technical_aspects(\"el sistema de gesti√≥n de documentos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
